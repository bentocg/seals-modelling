{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling seal population sizes with Pyro\n",
    "==========================================\n",
    "\n",
    "> Pipeline to model detection error for CNN output and estimate seal haul out patterns and population sizes using environmental covariates. The model works accross two scales: patch (spatial scale for seal habitat use); and subpatch (spatial scale for seal haulout behavior). Besides being biologically inspired, some of the covariate data are extract from course resolution sensors (e.g. MODIS), thus separating between patch and subpatch scale prevents pseudoreplication at the subpatch level. Pyro is a probabilistic programming language developed by Uber using PyTorch as its backend. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup\n",
    "-------------------------\n",
    "\n",
    "> Import a few packages, set random seed for reproducibility and enable output validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import geopandas as gpd\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading training data\n",
    "------------------------\n",
    "\n",
    "\n",
    "### Covariate list\n",
    "\n",
    "#### Patch (MODIS, 250m):\n",
    "\n",
    "1. Chlorophyl concentration\n",
    "2. Distance to continental shelf break\n",
    "3. Julian Day\n",
    "4. Time of the day\n",
    "5. Sea ice concentration\n",
    "\n",
    "#### Subpatch (WV03, 0.3m):\n",
    "\n",
    "1. Floe size\n",
    "2. Sea ice concentration\n",
    "\n",
    "#### Observed variables (Subpatch):\n",
    "\n",
    "1. Observed seals on ice (*N_obs*)\n",
    "2. True number of seals on ice (*N_ice*)\n",
    "\n",
    "#### Additional covariates?\n",
    "* Past season covariate values\n",
    "* Species occurrence (krill, seabirds, whales...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read patch level data\n",
    "data_patch = gpd.read_file('covariates/covariates_patch.dbf')\n",
    "\n",
    "# read subpatch level data\n",
    "data_subp = gpd.read_file('covariates/covariates_subp.dbf')\n",
    "\n",
    "# reformat data\n",
    "floe = [np.median(data_subp.loc[data_subp.patch_id == idx]['floe_size']) for idx in range(len(data_patch))]\n",
    "N_ice = [np.sum(data_subp.loc[data_subp.patch_id == idx]['n_ice']) for idx in range(len(data_patch))]\n",
    "cover = data_patch.sea_ice_co.values\n",
    "n_patches = len(floe)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition\n",
    "-----\n",
    "\n",
    "> Model definition includes model hierarchy and distribution of choice for each parameter. \n",
    "\n",
    "### Model equations\n",
    "\n",
    "##### Deterministic:\n",
    "$$ \\lambda_{total[i]} = Softplus(a_{\\lambda total} * X_{patch[i]} + b_{\\lambda total})$$\n",
    "\n",
    "$$ \\lambda_{fp[i, j]} = Softplus(a_{\\lambda fp} * X_{sub[i, j]} + b_{\\lambda fp})$$\n",
    "\n",
    "$$ \\alpha_{haul patch[i]} = Softplus(a_{\\alpha haul patch} * X_{patch[i]} + b_{\\alpha haul patch})$$\n",
    "\n",
    "$$ \\beta_{haul patch[i]} = S='oftplus(a_{\\beta haul patch} * X_{patch[i]} + b_{\\beta haul patch})$$\n",
    "\n",
    "$$ (\\rho_{sub [i, 0]} ... \\rho_{sub [i, j]}) = \\dfrac{Softplus(a_{\\rho sub} * (X_{sub[i, 0]} ... X_{sub[i, j]}))}{|Softplus(a_{\\rho sub} * (X_{sub[i, 0]} ... X_{sub[i, j]}))|}$$\n",
    "\n",
    "\n",
    "\n",
    "##### Probabilistic:\n",
    "\n",
    "$$ N_{total[i]} \\sim Poisson(\\lambda_{total[i]})$$\n",
    "\n",
    "$$ \\phi_{haul patch[i]} \\sim Beta(\\alpha_{haul patch[i]}, \\beta_{haul patch[i]}) $$\n",
    "\n",
    "$$ N_{ice patch[i]} \\sim Binomial(N_{total[i]}, \\phi_{haul_patch})$$\n",
    "\n",
    "$$ (\\phi_{haul sub[i, 0]} ... \\phi_{haul sub[i, j]}) \\sim Dirichlet(\\rho_{sub [i, 0]} ... \\rho_{sub [i, j]}) $$\n",
    "\n",
    "$$ (N_{ice[i, 0]} ...  N_{ice[i, j]}) \\sim Multinomial(N_{haul patch[i]}, \\phi_{haul sub[i, 0]} ... \\phi_{haul sub[i, j]})$$\n",
    "\n",
    "$$ FalsePositives_{[i, j]} \\sim Poisson(\\lambda_{fp[i, j]}) $$\n",
    "\n",
    "$$ N_{det[i, j]} \\sim Binomial \\left(N_{ice[i, j]} + \\dfrac{FalsePositives_{[i, j]}}{\\phi_{det[i, j]}},  \\phi_{det[i, j]} \\right) $$  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing simpler model formulations\n",
    "---\n",
    "\n",
    "### model v1 definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"472pt\" height=\"227pt\"\n",
       " viewBox=\"0.00 0.00 471.74 227.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 223)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-223 467.7376,-223 467.7376,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster806</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M161.1938,-8C161.1938,-8 303.1938,-8 303.1938,-8 309.1938,-8 315.1938,-14 315.1938,-20 315.1938,-20 315.1938,-143 315.1938,-143 315.1938,-149 309.1938,-155 303.1938,-155 303.1938,-155 161.1938,-155 161.1938,-155 155.1938,-155 149.1938,-149 149.1938,-143 149.1938,-143 149.1938,-20 149.1938,-20 149.1938,-14 155.1938,-8 161.1938,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"296.6938\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">806</text>\n",
       "</g>\n",
       "<!-- b_floe -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>b_floe</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"70.1938\" cy=\"-129\" rx=\"70.3881\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"70.1938\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">b_floe ~ Normal</text>\n",
       "</g>\n",
       "<!-- N_ice -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>N_ice</title>\n",
       "<ellipse fill=\"#d3d3d3\" stroke=\"#000000\" cx=\"232.1938\" cy=\"-57\" rx=\"74.9875\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"232.1938\" y=\"-53.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">N_ice ~ Binomial</text>\n",
       "</g>\n",
       "<!-- b_floe&#45;&gt;N_ice -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>b_floe&#45;&gt;N_ice</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M105.3454,-113.3771C129.3804,-102.6948 161.446,-88.4434 187.3238,-76.9422\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"188.8347,-80.1009 196.5514,-72.8411 185.9917,-73.7042 188.8347,-80.1009\"/>\n",
       "</g>\n",
       "<!-- a_cover -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>a_cover</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"147.1938\" cy=\"-201\" rx=\"75.2868\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"147.1938\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">a_cover ~ Normal</text>\n",
       "</g>\n",
       "<!-- N_total -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>N_total</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"232.1938\" cy=\"-129\" rx=\"74.187\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"232.1938\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">N_total ~ Poisson</text>\n",
       "</g>\n",
       "<!-- a_cover&#45;&gt;N_total -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>a_cover&#45;&gt;N_total</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M167.7699,-183.5708C178.5484,-174.4408 191.9176,-163.1163 203.6787,-153.1539\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"206.1443,-155.6524 211.5125,-146.5182 201.6198,-150.3111 206.1443,-155.6524\"/>\n",
       "</g>\n",
       "<!-- b_cover -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>b_cover</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"316.1938\" cy=\"-201\" rx=\"76.0865\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"316.1938\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">b_cover ~ Normal</text>\n",
       "</g>\n",
       "<!-- b_cover&#45;&gt;N_total -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>b_cover&#45;&gt;N_total</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M295.8597,-183.5708C285.208,-174.4408 271.9961,-163.1163 260.3733,-153.1539\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"262.5021,-150.3688 252.6317,-146.5182 257.9465,-155.6836 262.5021,-150.3688\"/>\n",
       "</g>\n",
       "<!-- s_floe -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>s_floe</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"394.1938\" cy=\"-129\" rx=\"69.5877\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"394.1938\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">s_floe ~ Normal</text>\n",
       "</g>\n",
       "<!-- s_floe&#45;&gt;N_ice -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>s_floe&#45;&gt;N_ice</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M359.0422,-113.3771C335.0071,-102.6948 302.9415,-88.4434 277.0638,-76.9422\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"278.3958,-73.7042 267.8362,-72.8411 275.5528,-80.1009 278.3958,-73.7042\"/>\n",
       "</g>\n",
       "<!-- N_total&#45;&gt;N_ice -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>N_total&#45;&gt;N_ice</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M232.1938,-110.8314C232.1938,-103.131 232.1938,-93.9743 232.1938,-85.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"235.6939,-85.4132 232.1938,-75.4133 228.6939,-85.4133 235.6939,-85.4132\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f0db31aa630>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from theano.tensor.nnet.nnet import sigmoid, softplus\n",
    "from pymc3 import Normal, Poisson, Binomial, sample, Model, model_to_graphviz, Metropolis\n",
    "                           \n",
    "\n",
    "with Model() as seals_model_v1:\n",
    "    \n",
    "    # priors for model parameters\n",
    "    b_floe = Normal('b_floe', 0, 100)\n",
    "    a_floe = Normal('s_floe', 0, 100)\n",
    "    \n",
    "    b_cover = Normal('b_cover', 0, 100)\n",
    "    a_cover = Normal('a_cover', 0, 100)\n",
    "    \n",
    "    # deterministic functions\n",
    "    lambda_total = softplus(a_cover * cover + b_cover)\n",
    "    phi_haul = sigmoid(a_floe * floe + b_floe)\n",
    "    \n",
    "    # total number of seals\n",
    "    N_total = Poisson('N_total', mu=lambda_total, shape=n_patches)\n",
    "    \n",
    "    # likelihood function\n",
    "    N_ice_pred = Binomial('N_ice', n=N_total, p=phi_haul, observed=N_ice)\n",
    "    \n",
    "model_to_graphviz(seals_model_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (6 chains in 6 jobs)\n",
      "CompoundStep\n",
      ">Metropolis: [N_total]\n",
      ">Metropolis: [a_cover]\n",
      ">Metropolis: [b_cover]\n",
      ">Metropolis: [s_floe]\n",
      ">Metropolis: [b_floe]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-abb0e4b7a3de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# run model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mseals_model_v1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mv1_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMetropolis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'b_floe'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's_floe'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.7/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0m_print_step_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mp_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not pickle model, sampling singlethreaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.7/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[0;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, **kwargs)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m     sampler = ps.ParallelSampler(\n\u001b[0;32m-> 1054\u001b[0;31m         \u001b[0mdraws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogressbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m     )\n\u001b[1;32m   1056\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.7/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, draws, tune, chains, cores, seeds, start_points, step_method, start_chain_num, progressbar)\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0mdraws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstart_chain_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             )\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         ]\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.7/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0mdraws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstart_chain_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             )\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         ]\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.7/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, draws, tune, step_method, chain, seed, start)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;31m# We fork right away, so that the main process can start tqdm threads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;31m# Something may have gone wrong during the fork / spawn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.7/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.7/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "from arviz import from_pymc3, plot_trace, rhat\n",
    "\n",
    "# run model\n",
    "with seals_model_v1:\n",
    "    v1_trace = sample(draws=500, tune=5000000, n_init=200000, step=Metropolis(), start={'b_floe': 0, 's_floe': 0}, cores=6)\n",
    "\n",
    "    \n",
    "# inspect output\n",
    "print(rhat(v1_trace))                                                          \n",
    "v1_output = from_pymc3(v1_trace)\n",
    "\n",
    "plot_trace(v1_output.posterior, var_names=['a_cover', 'b_cover'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model\n",
    "----\n",
    "\n",
    "> We use an Adam optimizer to train our model for a given number of steps. We define a function to inspect optimization.\n",
    "\n",
    "### *TODO :*\n",
    "* Add support for training on mini-batches\n",
    "* Check why values for **N_obs** fall outside of support sometimes\n",
    "* Check why model is sensible to starting values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "@poutine.broadcast\n",
    "def model_fun1(data):\n",
    "    # softplus transform as a link function\n",
    "    softplus = torch.nn.Softplus()\n",
    "\n",
    "    # extract patch and subpatch data\n",
    "    patch_cols = [idx for idx, ele in enumerate(data.columns) if 'patch' in ele]\n",
    "    subp_cols = [idx for idx, ele in enumerate(data.columns) if 'subp' in ele]\n",
    "    cov_patch = data.iloc[:, patch_cols]\n",
    "    cov_subp = data.iloc[:, subp_cols]\n",
    "\n",
    "    # unroll covariate data to Tensors\n",
    "    gt_N_ice = torch.Tensor([ele.cpu().numpy() for ele in data.true])\n",
    "    gt_N_obs = torch.Tensor([ele.cpu().numpy() for ele in data.obs])\n",
    "    cov_p = torch.randn([N_rows, 1, N_covs_patch])\n",
    "    cov_s = torch.randn([N_rows, N_cols, N_covs_subp])\n",
    "    for i in range(N_covs_patch):\n",
    "        cov_p[:, :, i] = torch.Tensor([ele.cpu().numpy() for ele in cov_patch.iloc[:, i]])\n",
    "    for i in range(N_covs_subp):\n",
    "        cov_s[:, :, i] = torch.Tensor([ele.cpu().numpy() for ele in cov_subp.iloc[:, i]])\n",
    "\n",
    "    \n",
    "    # parameter names -- patch\n",
    "    patch_par_names = []\n",
    "    for par in ['a_', 'b_']:\n",
    "        patch_par_names.extend([\n",
    "            par + ele for ele in ['lambda_total', 'alpha_haul_prob_patch', 'beta_haul_prob_patch']\n",
    "        ])\n",
    "\n",
    "    # parameter names -- subpatch\n",
    "    subp_par_names = []\n",
    "    for par in ['a_', 'b_']:\n",
    "        subp_par_names.extend([\n",
    "            par + ele for ele in [\n",
    "                'lambda_false_pos', 'alpha_haul_prob_subp', 'beta_haul_prob_subp', 'alpha_det',\n",
    "                'beta_det'\n",
    "            ]\n",
    "        ])\n",
    "    \n",
    "    # parameter starting values\n",
    "    alphas_patch = pyro.param('alphas_patch', torch.Tensor([1] * len(patch_par_names)), constraint=constraints.positive)\n",
    "    betas_patch = pyro.param('betas_patch', torch.Tensor([1] * len(patch_par_names)), constraint=constraints.positive)\n",
    "    alphas_subp = pyro.param('alphas_subp', torch.Tensor([1] * len(subp_par_names)), constraint=constraints.positive)\n",
    "    betas_subp = pyro.param('betas_subp', torch.Tensor([1] * len(subp_par_names)), constraint=constraints.positive)\n",
    "\n",
    "    patch_params = {\n",
    "        ele: pyro.sample(\n",
    "            ele,\n",
    "            dist.Gamma(alphas_patch[idx], betas_patch[idx]).expand([N_covs_patch]).independent(1))\n",
    "        for idx, ele in enumerate(patch_par_names)\n",
    "    }\n",
    "\n",
    "    \n",
    "    subp_params = {\n",
    "        ele: pyro.sample(\n",
    "            ele,\n",
    "            dist.Gamma(alphas_subp[idx], betas_subp[idx]).expand([N_covs_subp]).independent(1))\n",
    "        for idx, ele in enumerate(subp_par_names)\n",
    "    }\n",
    "\n",
    "    # create plates for parallelizing\n",
    "    x = pyro.plate('x', size=N_rows, dim=-2)\n",
    "    y = pyro.plate('y', size=N_cols, dim=-1)\n",
    "\n",
    "    # patch loop\n",
    "    with x:\n",
    "        # deterministic linear functions\n",
    "        lambda_total = softplus(\n",
    "            torch.sum(patch_params['a_lambda_total'] * cov_p + patch_params['b_lambda_total']))\n",
    "        alpha_haul_prob_patch = softplus(\n",
    "            torch.sum(patch_params['a_alpha_haul_prob_patch'] * cov_p +\n",
    "                      patch_params['b_alpha_haul_prob_patch']))\n",
    "        beta_haul_prob_patch = softplus(\n",
    "            torch.sum(patch_params['a_beta_haul_prob_patch'] * cov_p +\n",
    "                      patch_params['b_beta_haul_prob_patch']))\n",
    "\n",
    "        # draw haul out probability for patches\n",
    "        haul_prob_patch = pyro.sample('haul_prob_patch',\n",
    "                                      dist.Beta(alpha_haul_prob_patch, beta_haul_prob_patch))\n",
    "\n",
    "        # get total number of seals for patches\n",
    "        N_total = pyro.sample('N_total', dist.Poisson(lambda_total))\n",
    "        \n",
    "        # get totao number of hauled out seals\n",
    "        N_total_haul = pyro.sample('N_total_haul', dist.Binomial(N_total, haul_prob_patch))\n",
    "\n",
    "    # subpatch loop\n",
    "    with x, y:\n",
    "        # deterministic linear functions\n",
    "        lambda_false_pos = softplus(\n",
    "            torch.sum(subp_params['a_lambda_false_pos'] * cov_s +\n",
    "                      subp_params['b_lambda_false_pos']))\n",
    "        alpha_haul_prob_subp = softplus(\n",
    "            torch.sum(subp_params['a_alpha_haul_prob_subp'] * cov_s +\n",
    "                      subp_params['b_alpha_haul_prob_subp']))\n",
    "        beta_haul_prob_subp = softplus(\n",
    "            torch.sum(subp_params['a_beta_haul_prob_subp'] * cov_s +\n",
    "                      subp_params['b_beta_haul_prob_subp']))\n",
    "        alpha_det_subp = softplus(\n",
    "            torch.sum(subp_params['a_alpha_det'] * cov_s + subp_params['b_alpha_det']))\n",
    "        beta_det_subp = softplus(\n",
    "            torch.sum(subp_params['a_beta_det'] * cov_s + subp_params['b_beta_det']))\n",
    "\n",
    "        # draw haul out probability for subpatches (subpatch specific)\n",
    "        haul_prob_subp = pyro.sample('haul_prob_subp',\n",
    "                                     dist.Gamma(alpha_haul_prob_subp, beta_haul_prob_subp))\n",
    "        det_prob_subp = pyro.sample('det_subp', dist.Beta(alpha_det_subp, beta_det_subp))\n",
    "        false_pos = pyro.sample('false_pos', dist.Poisson(lambda_false_pos))\n",
    "        \n",
    "\n",
    "    if observe:\n",
    "        for i in pyro.plate('rows', N_rows):\n",
    "            N_ice = pyro.sample(f'N_ice_{i}',\n",
    "                                dist.DirichletMultinomial(concentration=haul_prob_subp[i, :],\n",
    "                                                          total_count=N_total_haul[i],\n",
    "                                                          validate_args=False),\n",
    "                                obs=gt_N_ice[i, :])\n",
    "            for j in pyro.plate(f'cols_{i}', N_cols):\n",
    "                pyro.sample(f'N_obs_{i}_{j}',\n",
    "                            dist.Binomial(total_count=max(0, (N_ice[j] +\n",
    "                                                       false_pos[i, j] / det_prob_subp[i, j]).int()),\n",
    "                                          probs=det_prob_subp[i, j]),\n",
    "                            obs=gt_N_obs[i, j])"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:geospatial]",
   "language": "python",
   "name": "conda-env-geospatial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
